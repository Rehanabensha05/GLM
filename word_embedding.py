# -*- coding: utf-8 -*-
"""word_embedding.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sTHzFcbdCPUJq8njFUzj1xQ9k42rty2-
"""

# Libraries
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.cluster import KMeans
from gensim.models import Word2Vec
from scipy.spatial.distance import jaccard

# Sample Data
texts = ["Telecommunication, often used in its plural form or abbreviated as telecom, is the transmission of information with an immediacy comparable to face-to-face communication. As such, slow communications technologies like postal mail and pneumatic tubes are excluded from the definition.[1][2] Many transmission media have been used for telecommunications throughout history, from smoke signals, beacons, semaphore telegraphs, signal flags, and optical heliographs to wires and empty space made to carry electromagnetic signals. These paths of transmission may be divided into communication channels for multiplexing, allowing for a single medium to transmit several concurrent communication sessions. Several methods of long-distance communication before the modern era used sounds like coded drumbeats, the blowing of horns, and whistles. Long-distance technologies invented during the 20th and 21st centuries generally use electric power, and include the telegraph, telephone, television, and radio."]
texts_tokenized = [text.lower().split() for text in texts]

#  Jaccard similarity
def jaccard_similarity(x, y):
    """Returns the Jaccard similarity between two lists."""
    set_x = set(x)
    set_y = set(y)
    intersection_cardinality = len(set_x.intersection(set_y))
    union_cardinality = len(set_x.union(set_y))
    return intersection_cardinality / float(union_cardinality)


sentence1 = """Telecommunication, often used in its plural form or abbreviated as telecom,
is the transmission of information with an immediacy comparable to face-to-face communication.
As such, slow communications technologies like postal mail and pneumatic tubes are excluded
from the definition. Many transmission media have been used for telecommunications throughout history,
from smoke signals, beacons, semaphore telegraphs, signal flags, and optical heliographs to wires and
empty space made to carry electromagnetic signals. These paths of transmission may be divided into
communication channels for multiplexing, allowing for a single medium to transmit several concurrent
communication sessions. Several methods of long-distance communication before the modern era used
sounds like coded drumbeats, the blowing of horns, and whistles. Long-distance technologies invented
during the 20th and 21st centuries generally use electric power, and include the telegraph, telephone,
television, and radio."""

# Another sentence
sentence2 = "Telecommunication includes the transmission of information through various media like telephone, television, and radio."

# Tokenizing and converting to lowercase
tokens1 = sentence1.lower().split()
tokens2 = sentence2.lower().split()

# Calculating Jaccard similarity
similarity = jaccard_similarity(tokens1, tokens2)

print(f"Jaccard Similarity: {similarity}")

from sklearn.feature_extraction.text import CountVectorizer
from math import sqrt

# Function to calculate Euclidean distance
def euclidean_distance(x, y):
    """Returns the Euclidean distance between two lists."""
    return sqrt(sum((a - b) ** 2 for a, b in zip(x, y)))
    # Convert sentences to Bag of Words vectors
vectorizer = CountVectorizer()
vectors = vectorizer.fit_transform([sentence1, sentence2]).toarray()

# Display the vectors
print("Vector for sentence 1:", vectors[0])
print("Vector for sentence 2:", vectors[1])

# Calculate Euclidean distance
distance = euclidean_distance(vectors[0], vectors[1])

print(f"Euclidean Distance: {distance}")

!pip install spacy
!python -m spacy download en_core_web_sm

import spacy
from scipy.spatial.distance import euclidean

# Load the spaCy model
nlp = spacy.load("en_core_web_sm")

# Process sentences and obtain their embeddings
sentences = ["The bag is empty", "There is nothing in the bag"]
embeddings = [nlp(sentence).vector for sentence in sentences]

# Compute the Euclidean distance between the embeddings
distance = euclidean(embeddings[0], embeddings[1])

print(f"Euclidean Distance: {distance}")

import math

def distance_to_similarity(distance):
    """Convert distance to similarity using an exponential function."""
    return 1 / math.exp(distance)

# Example usage
distance = 2.5  # Replace with your actual distance value
similarity = distance_to_similarity(distance)

print(f"Similarity: {similarity}")

from collections import Counter
# Preprocess the text
# Remove punctuation and convert to lowercase
import string

# Remove punctuation from the sentence
translator = str.maketrans('', '', string.punctuation)
cleaned_sentence = sentence1.translate(translator)

# Tokenize the cleaned sentence
words = cleaned_sentence.lower().split()

# Create a Bag of Words representation using Counter
bag_of_words = Counter(words)

# Print the Bag of Words
print(bag_of_words)

# Plot the heatmap
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
# Convert Bag of Words to DataFrame
df_bow = pd.DataFrame.from_dict(bag_of_words, orient='index', columns=['Count'])
df_bow = df_bow.T  # Transpose to have words as columns
# Plot the heatmap
# Plot the heatmap
plt.figure(figsize=(12, 2))  # Adjust size as needed
sns.heatmap(df_bow, annot=True, cmap='YlGnBu', cbar=True, xticklabels=df_bow.columns)
plt.xlabel('Words')
plt.ylabel('Sentence')
plt.title('Bag of Words Heatmap')
plt.show()

from sklearn.feature_extraction.text import CountVectorizer

# Define the sentence
sentence = """Telecommunication, often used in its plural form or abbreviated as telecom,
is the transmission of information with an immediacy comparable to face-to-face communication.
As such, slow communications technologies like postal mail and pneumatic tubes are excluded
from the definition. Many transmission media have been used for telecommunications throughout history,
from smoke signals, beacons, semaphore telegraphs, signal flags, and optical heliographs to wires and
empty space made to carry electromagnetic signals. These paths of transmission may be divided into
communication channels for multiplexing, allowing for a single medium to transmit several concurrent
communication sessions. Several methods of long-distance communication before the modern era used
sounds like coded drumbeats, the blowing of horns, and whistles. Long-distance technologies invented
during the 20th and 21st centuries generally use electric power, and include the telegraph, telephone,
television, and radio."""

# Initialize the CountVectorizer
vectorizer = CountVectorizer(stop_words='english')  # Optional: remove common English stop words

# Fit and transform the sentence
X = vectorizer.fit_transform([sentence])

# Get feature names (words)
feature_names = vectorizer.get_feature_names_out()

# Convert the result to an array
X_array = X.toarray()

# Print feature names
print("Feature Names (Vocabulary):")
print(feature_names)

# Print Bag of Words matrix
print("\nBag of Words Matrix:")
print(X_array)

from sklearn.feature_extraction.text import TfidfVectorizer
# Initialize the TfidfVectorizer
vectorizer = TfidfVectorizer(stop_words='english')

# Fit and transform the sentence
X = vectorizer.fit_transform([sentence])

# Get feature names (words)
feature_names = vectorizer.get_feature_names_out()

# Convert the result to an array
X_array = X.toarray()

# Print feature names
print("Feature Names (Vocabulary):")
print(feature_names)

# Print TF-IDF matrix
print("\nTF-IDF Matrix:")
print(X_array)

#word2vec
import spacy
nlp = spacy.load("en_core_web_sm")

# Assuming 'sentences' is already defined as in your provided code
docs = list(nlp.pipe(sentence))

print(docs)

import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from gensim.models import Word2Vec
from nltk.tokenize import word_tokenize
import nltk
nltk.download('punkt')
sentences = [
    "Telecommunication, often used in its plural form or abbreviated as telecom, is the transmission of information with an immediacy comparable to face-to-face communication.",
    "As such, slow communications technologies like postal mail and pneumatic tubes are excluded from the definition.",
    "Many transmission media have been used for telecommunications throughout history, from smoke signals, beacons, semaphore telegraphs, signal flags, and optical heliographs to wires and empty space made to carry electromagnetic signals.",
    "These paths of transmission may be divided into communication channels for multiplexing, allowing for a single medium to transmit several concurrent communication sessions.",
    "Several methods of long-distance communication before the modern era used sounds like coded drumbeats, the blowing of horns, and whistles.",
    "Long-distance technologies invented during the 20th and 21st centuries generally use electric power, and include the telegraph, telephone, television, and radio."
]

# Tokenize sentences
tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]

# Train Word2Vec model
model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)

# Get word vectors for all unique words
word_vectors = [model.wv[word] for word in model.wv.index_to_key]

# Step 3: Calculate WCSS for different numbers of clusters
wcss = []
max_clusters = 10  # Maximum number of clusters to consider
cluster_range = range(2, 11)  # From 2 to 10 clusters

for num_clusters in cluster_range:
    kmeans = KMeans(n_clusters=num_clusters, random_state=42)
    kmeans.fit(word_vectors)
    wcss.append(kmeans.inertia_)

# Step 1: Calculate WCSS and Silhouette Scores for different numbers of clusters
from sklearn.metrics import silhouette_score
wcss = []
silhouette_scores = []
max_clusters = 10  # Maximum number of clusters to consider

for num_clusters in range(2, max_clusters + 1):  # Start from 2 to avoid single cluster case
    kmeans = KMeans(n_clusters=num_clusters, random_state=42)
    kmeans.fit(word_vectors)
    wcss.append(kmeans.inertia_)

# Step 2: Plot WCSS values to use the Elbow Method
plt.figure(figsize=(12, 6))

# Plot WCSS
plt.subplot(1, 2, 1)
plt.plot(range(2, max_clusters + 1), wcss, marker='o')
plt.title('Elbow Method for Optimal Number of Clusters')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.grid(True)

# Calculate silhouette score
silhouette_avg = silhouette_score(word_vectors, kmeans.labels_)
silhouette_scores.append(silhouette_avg)
print(f'Number of clusters: {num_clusters}, Silhouette Score: {silhouette_avg}')